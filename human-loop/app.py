import streamlit as st
import uuid
import time
import json
from typing import TypedDict, Optional, Dict, Any, List
from dataclasses import dataclass
from langgraph.constants import START, END
from langgraph.graph import StateGraph
from langgraph.types import interrupt, Command
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_community.chat_models import ChatOllama

# Configuration de la page Streamlit
st.set_page_config(
    page_title="ğŸ¤– Assistant IA avec Interruptions LangGraph",
    page_icon="ğŸ”„",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personnalisÃ© pour amÃ©liorer l'interface
st.markdown("""
<style>
    .interrupt-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 20px;
        border-radius: 10px;
        color: white;
        margin: 10px 0;
    }
    .status-success {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        color: #155724;
        padding: 10px;
        border-radius: 5px;
        margin: 5px 0;
    }
    .status-waiting {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        color: #856404;
        padding: 10px;
        border-radius: 5px;
        margin: 5px 0;
    }
    .status-error {
        background-color: #f8d7da;
        border: 1px solid #f5c6cb;
        color: #721c24;
        padding: 10px;
        border-radius: 5px;
        margin: 5px 0;
    }
    .event-message {
        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        border-radius: 10px;
        padding: 15px;
        margin: 10px 0;
        color: white;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    .event-header {
        font-weight: bold;
        font-size: 1.1em;
        margin-bottom: 10px;
        text-transform: uppercase;
        letter-spacing: 1px;
    }
    .event-content {
        line-height: 1.6;
    }
    .event-metadata {
        background: rgba(255, 255, 255, 0.1);
        border-radius: 5px;
        padding: 10px;
        margin-top: 10px;
        font-size: 0.9em;
    }
</style>
""", unsafe_allow_html=True)

# DÃ©finition de l'Ã©tat du graphe
class WorkflowState(TypedDict):
    user_request: str
    analysis: str
    generated_content: str
    human_feedback: str
    final_result: str
    step: str
    metadata: Dict[str, Any]
    events: List[Dict[str, Any]]

def dispatch_event(event_type: str, content: str, metadata: Dict[str, Any] = None) -> Dict[str, Any]:
    """Dispatch un Ã©vÃ©nement personnalisÃ©"""
    return {
        "type": event_type,
        "data": {
            "content": content,
            "timestamp": time.time(),
            "metadata": metadata or {}
        }
    }

def update_workflow_events(events: List[Dict[str, Any]]):
    """Met Ã  jour les Ã©vÃ©nements du workflow dans l'Ã©tat de session"""
    if 'events' not in st.session_state.workflow_state:
        st.session_state.workflow_state['events'] = []
    
    # Add new events that aren't already present
    for event in events:
        event_id = f"{event['type']}_{event['data']['timestamp']}"
        existing_events = st.session_state.workflow_state['events']
        
        if not any(f"{e['type']}_{e['data']['timestamp']}" == event_id for e in existing_events):
            st.session_state.workflow_state['events'].append(event)

def process_workflow_events(events: List[Dict[str, Any]]):
    """Traite et affiche les Ã©vÃ©nements du workflow en temps rÃ©el"""
    for event in events:
        # Add event to messages if not already present
        event_id = f"{event['type']}_{event['data']['timestamp']}"
        existing_events = [msg for msg in st.session_state.messages if msg.get('type') == 'event']
        
        if not any(f"{msg['event_type']}_{msg['timestamp']}" == event_id for msg in existing_events):
            st.session_state.messages.append({
                'type': 'event',
                'event_type': event['type'],
                'content': event['data']['content'],
                'timestamp': event['data']['timestamp'],
                'metadata': event['data'].get('metadata', {})
            })
            
            # Force a rerun to show the event immediately
            st.rerun()

# Initialisation de l'Ã©tat Streamlit
def init_session_state():
    """Initialise l'Ã©tat de la session Streamlit"""
    if 'workflow_state' not in st.session_state:
        st.session_state.workflow_state = {
            'current_thread_id': None,
            'interrupted': False,
            'interrupt_data': None,
            'workflow_completed': False,
            'execution_history': [],
            'current_step': 'idle',
            'events': []
        }
    
    if 'graph' not in st.session_state:
        st.session_state.graph = None
    
    if 'messages' not in st.session_state:
        st.session_state.messages = []

# Configuration du modÃ¨le LLM
@st.cache_resource
def get_llm():
    """Initialise le modÃ¨le LLM via LM Studio (Llama-3.2-3b-instruct)"""
    try:
        # Utilise LM Studio local avec le modÃ¨le llama-3.2-3b-instruct
        return ChatOllama(
            model="llama-3.2-3b-instruct",
            temperature=0.7,
            base_url="http://localhost:1234"  # Change if your LM Studio runs on a different port
        )
    except Exception as e:
        st.error(f"Erreur d'initialisation LLM: {e}")
        return None

# NÅ“uds du workflow LangGraph
def analyze_request_node(state: WorkflowState) -> WorkflowState:
    """Analyse la demande utilisateur"""
    print(f"ğŸ” Analyse de la demande: {state['user_request']}")
    
    # Simulation d'analyse (vous pouvez utiliser un vrai LLM ici)
    request = state['user_request'].lower()
    
    if any(word in request for word in ['rÃ©sumÃ©', 'summary', 'synthÃ¨se']):
        analysis = "Demande de gÃ©nÃ©ration de rÃ©sumÃ© dÃ©tectÃ©e"
        content_type = "summary"
    elif any(word in request for word in ['email', 'mail', 'message']):
        analysis = "Demande de rÃ©daction d'email dÃ©tectÃ©e"
        content_type = "email"
    elif any(word in request for word in ['code', 'script', 'programme']):
        analysis = "Demande de gÃ©nÃ©ration de code dÃ©tectÃ©e"
        content_type = "code"
    else:
        analysis = "Demande gÃ©nÃ©rale de contenu dÃ©tectÃ©e"
        content_type = "general"
    
    # Dispatch custom event
    analysis_event = dispatch_event(
        "analysis_completed",
        f"ğŸ” **Analyse terminÃ©e**\n\n**Type de contenu dÃ©tectÃ©:** {content_type}\n**Analyse:** {analysis}",
        {"content_type": content_type, "analysis": analysis}
    )
    
    # Add event to state
    events = state.get("events", [])
    events.append(analysis_event)
    
    return {
        **state,
        "analysis": analysis,
        "step": "analyzed",
        "metadata": {**state.get("metadata", {}), "content_type": content_type},
        "events": events
    }

def generate_content_node(state: WorkflowState) -> WorkflowState:
    """GÃ©nÃ¨re le contenu initial avec l'IA"""
    print(f"ğŸ¤– GÃ©nÃ©ration de contenu pour: {state['analysis']}")
    
    try:
        llm = get_llm()
        content_type = state["metadata"].get("content_type", "general")
        
        # Templates de prompts selon le type de contenu
        prompts = {
            "summary": f"CrÃ©e un rÃ©sumÃ© professionnel sur le sujet suivant: {state['user_request']}",
            "email": f"RÃ©dige un email professionnel concernant: {state['user_request']}",
            "code": f"GÃ©nÃ¨re du code Python pour: {state['user_request']}",
            "general": f"CrÃ©e du contenu pertinent pour: {state['user_request']}"
        }
        
        prompt = prompts.get(content_type, prompts["general"])
        
        if llm:
            response = llm.invoke([HumanMessage(content=prompt)])
            generated_content = response.content
        else:
            # Contenu de fallback si LLM indisponible
            generated_content = f"Contenu gÃ©nÃ©rÃ© pour: {state['user_request']}\n\nCeci est un exemple de contenu qui serait normalement gÃ©nÃ©rÃ© par l'IA. Vous pouvez l'Ã©diter selon vos besoins."
        
    except Exception as e:
        generated_content = f"Erreur de gÃ©nÃ©ration: {str(e)}\n\nContenu de secours gÃ©nÃ©rÃ© localement."
    
    # Dispatch custom event
    generation_event = dispatch_event(
        "content_generated",
        f"ğŸ¤– **Contenu gÃ©nÃ©rÃ©**\n\n**Type:** {content_type}\n\n**Contenu:**\n{generated_content[:500]}{'...' if len(generated_content) > 500 else ''}",
        {"content_type": content_type, "content_length": len(generated_content)}
    )
    
    # Add event to state
    events = state.get("events", [])
    events.append(generation_event)
    
    return {
        **state,
        "generated_content": generated_content,
        "step": "generated",
        "events": events
    }

def human_review_node(state: WorkflowState) -> WorkflowState:
    """NÅ“ud d'interruption pour rÃ©vision humaine"""
    print("ğŸ‘¤ Interruption pour rÃ©vision humaine...")
    
    # Dispatch custom event for human review request
    review_event = dispatch_event(
        "human_review_requested",
        f"ğŸ‘¤ **RÃ©vision humaine requise**\n\n**Demande:** {state['user_request']}\n**Type de contenu:** {state['metadata'].get('content_type', 'general')}\n\nLe contenu gÃ©nÃ©rÃ© attend votre validation et modification si nÃ©cessaire.",
        {"content_type": state["metadata"].get("content_type", "general")}
    )
    
    # Add event to state
    events = state.get("events", [])
    events.append(review_event)
    
    # CrÃ©er les donnÃ©es d'interruption
    interrupt_payload = {
        "task": "Veuillez rÃ©viser et modifier le contenu gÃ©nÃ©rÃ© si nÃ©cessaire",
        "user_request": state["user_request"],
        "analysis": state["analysis"],
        "generated_content": state["generated_content"],
        "content_type": state["metadata"].get("content_type", "general"),
        "timestamp": time.time()
    }
    
    # INTERRUPTION : Le workflow s'arrÃªte ici et attend l'input humain
    result = interrupt(interrupt_payload)
    
    # Cette ligne ne s'exÃ©cute qu'aprÃ¨s la reprise avec Command(resume=...)
    return {
        **state,
        "human_feedback": result.get("human_feedback", ""),
        "generated_content": result.get("edited_content", state["generated_content"]),
        "step": "reviewed",
        "events": events
    }

def finalize_content_node(state: WorkflowState) -> WorkflowState:
    """Finalise le contenu aprÃ¨s rÃ©vision humaine"""
    print("âœ… Finalisation du contenu...")
    
    # IntÃ©grer le feedback humain
    final_result = state["generated_content"]
    
    if state.get("human_feedback"):
        final_result += f"\n\n--- Commentaires de rÃ©vision ---\n{state['human_feedback']}"
    
    # Dispatch custom event for finalization
    finalization_event = dispatch_event(
        "content_finalized",
        f"âœ… **Contenu finalisÃ©**\n\n**Demande originale:** {state['user_request']}\n**Feedback humain:** {'Oui' if state.get('human_feedback') else 'Non'}\n\nLe workflow est terminÃ© avec succÃ¨s !",
        {"has_feedback": bool(state.get("human_feedback")), "final_length": len(final_result)}
    )
    
    # Add event to state
    events = state.get("events", [])
    events.append(finalization_event)
    
    return {
        **state,
        "final_result": final_result,
        "step": "finalized",
        "events": events
    }

# Construction du graphe LangGraph
@st.cache_resource
def create_workflow():
    """CrÃ©e et compile le workflow LangGraph avec gestion des interruptions"""
    builder = StateGraph(WorkflowState)
    
    # Ajouter les nÅ“uds
    builder.add_node("analyze_request", analyze_request_node)
    builder.add_node("generate_content", generate_content_node)
    builder.add_node("human_review", human_review_node)
    builder.add_node("finalize_content", finalize_content_node)
    
    # DÃ©finir le flow
    builder.set_entry_point("analyze_request")
    builder.add_edge("analyze_request", "generate_content")
    builder.add_edge("generate_content", "human_review")
    builder.add_edge("human_review", "finalize_content")
    builder.add_edge("finalize_content", END)
    
    # Compiler avec checkpointer pour supporter les interruptions
    checkpointer = MemorySaver()
    return builder.compile(checkpointer=checkpointer)

# Interface Streamlit principale
def main():
    init_session_state()
    
    # Titre et description
    st.title("ğŸ¤– Assistant IA avec Interruptions LangGraph")
    st.markdown("---")
    st.markdown("**Workflow intelligent avec validation humaine en temps rÃ©el**")
    
    # Sidebar pour les contrÃ´les
    with st.sidebar:
        st.header("ğŸ›ï¸ ContrÃ´les du Workflow")
        
        # Statut actuel
        status = st.session_state.workflow_state['current_step']
        if status == 'idle':
            st.markdown('<div class="status-success">ğŸ’¤ En attente</div>', unsafe_allow_html=True)
        elif status == 'processing':
            st.markdown('<div class="status-waiting">âš™ï¸ Traitement en cours...</div>', unsafe_allow_html=True)
        elif status == 'interrupted':
            st.markdown('<div class="status-waiting">â¸ï¸ En attente de rÃ©vision</div>', unsafe_allow_html=True)
        elif status == 'completed':
            st.markdown('<div class="status-success">âœ… TerminÃ©</div>', unsafe_allow_html=True)
        
        st.markdown("---")
        
        # Panel des Ã©vÃ©nements
        st.subheader("ğŸ“Š Ã‰vÃ©nements du Workflow")
        events = st.session_state.workflow_state.get('events', [])
        
        if events:
            for i, event in enumerate(events[-5:]):  # Show last 5 events
                event_type = event.get('type', 'unknown')
                timestamp = event.get('data', {}).get('timestamp', 0)
                time_str = time.strftime('%H:%M:%S', time.localtime(timestamp))
                
                # Color coding for different event types
                if 'analysis' in event_type:
                    icon = "ğŸ”"
                    color = "success"
                elif 'generated' in event_type:
                    icon = "ğŸ¤–"
                    color = "info"
                elif 'review' in event_type:
                    icon = "ğŸ‘¤"
                    color = "warning"
                elif 'finalized' in event_type:
                    icon = "âœ…"
                    color = "success"
                else:
                    icon = "ğŸ“‹"
                    color = "info"
                
                st.markdown(f"""
                <div class="status-{color}">
                    {icon} {event_type.replace('_', ' ').title()}
                    <br><small>{time_str}</small>
                </div>
                """, unsafe_allow_html=True)
        else:
            st.info("Aucun Ã©vÃ©nement pour le moment")
        
        st.markdown("---")
        
        # Bouton reset
        if st.button("ğŸ”„ Nouveau Workflow", use_container_width=True):
            reset_workflow()
        
        # Informations de debug
        with st.expander("ğŸ”§ Debug Info"):
            st.json({
                "thread_id": st.session_state.workflow_state.get('current_thread_id'),
                "interrupted": st.session_state.workflow_state.get('interrupted', False),
                "completed": st.session_state.workflow_state.get('workflow_completed', False),
                "current_step": st.session_state.workflow_state.get('current_step', 'idle'),
                "events_count": len(events)
            })
    
    # Interface principale
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("ğŸ’¬ Interface Utilisateur")
        
        # Progress indicator for workflow steps
        if st.session_state.workflow_state['current_step'] != 'idle':
            st.subheader("ğŸ“ˆ Progression du Workflow")
            
            steps = ['start', 'analyzed', 'generated', 'reviewed', 'finalized']
            current_step = st.session_state.workflow_state['current_step']
            
            if current_step in steps:
                current_index = steps.index(current_step)
                progress = (current_index + 1) / len(steps)
                
                st.progress(progress)
                
                # Show step labels
                cols = st.columns(len(steps))
                for i, step in enumerate(steps):
                    with cols[i]:
                        if i <= current_index:
                            st.markdown(f"âœ… {step.title()}")
                        else:
                            st.markdown(f"â³ {step.title()}")
        
        render_main_interface()
    
    with col2:
        st.header("ğŸ” Panneau de RÃ©vision")
        render_review_panel()

def render_main_interface():
    """Affiche l'interface principale de saisie"""
    
    # Afficher l'historique des messages
    for msg in st.session_state.messages:
        if msg['type'] == 'user':
            st.chat_message("user").write(msg['content'])
        elif msg['type'] == 'assistant':
            st.chat_message("assistant").write(msg['content'])
        elif msg['type'] == 'system':
            st.info(f"ğŸ”„ {msg['content']}")
        elif msg['type'] == 'event':
            # Display custom events with special styling
            st.markdown(f"""
            <div class="event-message">
                <div class="event-header">ğŸ¯ {msg['event_type'].replace('_', ' ').title()}</div>
                <div class="event-content">{msg['content']}</div>
            </div>
            """, unsafe_allow_html=True)
            
            # Show metadata in an expander
            if msg.get('metadata'):
                with st.expander("ğŸ“Š MÃ©tadonnÃ©es de l'Ã©vÃ©nement"):
                    st.json(msg['metadata'])
    
    # Interface de saisie
    if not st.session_state.workflow_state.get('interrupted', False):
        
        # Zone de saisie principale
        user_input = st.chat_input("DÃ©crivez ce que vous voulez que l'IA gÃ©nÃ¨re...")
        
        if user_input:
            handle_user_request(user_input)
        
        # Boutons d'exemples
        st.markdown("**ğŸ’¡ Exemples rapides:**")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ğŸ“ RÃ©sumÃ© d'article"):
                handle_user_request("CrÃ©e un rÃ©sumÃ© professionnel sur l'intelligence artificielle")
        
        with col2:
            if st.button("ğŸ“§ Email professionnel"):
                handle_user_request("RÃ©dige un email de suivi client")
        
        with col3:
            if st.button("ğŸ’» Code Python"):
                handle_user_request("GÃ©nÃ¨re du code pour analyser un CSV")

def render_review_panel():
    """Affiche le panneau de rÃ©vision pour les interruptions"""
    
    if st.session_state.workflow_state.get('interrupted', False):
        interrupt_data = st.session_state.workflow_state.get('interrupt_data')
        
        if interrupt_data:
            st.markdown('<div class="interrupt-card">', unsafe_allow_html=True)
            st.markdown("### â¸ï¸ RÃ©vision Requise")
            st.markdown("Le workflow attend votre validation...")
            st.markdown('</div>', unsafe_allow_html=True)
            
            # Afficher les informations
            st.markdown("**ğŸ“‹ Demande originale:**")
            ui_data = interrupt_data[-1].value
            st.info(ui_data.get('user_request', 'N/A'))
            
            st.markdown("**ğŸ” Analyse:**")

            st.write(ui_data.get('analysis', 'N/A'))
            
            st.markdown("**ğŸ¤– Contenu gÃ©nÃ©rÃ©:**")
            generated_content = ui_data.get('generated_content', '')
            
            # Zone d'Ã©dition du contenu
            edited_content = st.text_area(
                "Ã‰ditez le contenu si nÃ©cessaire:",
                value=generated_content,
                height=300,
                key="content_editor"
            )
            
            # Feedback optionnel
            human_feedback = st.text_area(
                "ğŸ’¬ Commentaires (optionnel):",
                placeholder="Ajoutez vos commentaires sur les modifications...",
                height=100,
                key="feedback_editor"
            )
            
            # Boutons d'action
            col1, col2 = st.columns(2)
            
            with col1:
                if st.button("âœ… Approuver", use_container_width=True, type="primary"):
                    resume_workflow(edited_content, human_feedback)
            
            with col2:
                if st.button("âŒ Rejeter", use_container_width=True):
                    reject_workflow(human_feedback)
    
    else:
        st.info("ğŸ”„ Aucune rÃ©vision en attente")
        
        # Historique des exÃ©cutions
        if st.session_state.workflow_state.get('execution_history'):
            with st.expander("ğŸ“š Historique"):
                for i, execution in enumerate(st.session_state.workflow_state['execution_history']):
                    st.write(f"**ExÃ©cution {i+1}:** {execution.get('user_request', 'N/A')[:50]}...")

def handle_user_request(user_input: str):
    """Traite une nouvelle demande utilisateur"""
    
    # Ajouter le message utilisateur
    st.session_state.messages.append({
        'type': 'user',
        'content': user_input,
        'timestamp': time.time()
    })
    
    # Initialiser le workflow
    st.session_state.workflow_state.update({
        'current_thread_id': str(uuid.uuid4()),
        'interrupted': False,
        'workflow_completed': False,
        'current_step': 'processing'
    })
    
    # CrÃ©er ou rÃ©cupÃ©rer le graphe
    if st.session_state.graph is None:
        st.session_state.graph = create_workflow()
    
    # PrÃ©parer l'Ã©tat initial
    initial_state = {
        "user_request": user_input,
        "analysis": "",
        "generated_content": "",
        "human_feedback": "",
        "final_result": "",
        "step": "start",
        "metadata": {},
        "events": []
    }
    
    # Configuration du thread
    config = {"configurable": {"thread_id": st.session_state.workflow_state['current_thread_id']}}
    
    try:
        # ExÃ©cuter jusqu'Ã  l'interruption
        with st.spinner("ğŸ”„ Traitement en cours..."):
            result = st.session_state.graph.invoke(initial_state, config=config)
        
        # Process events and add them to messages
        if "events" in result:
            # Update workflow state events
            update_workflow_events(result["events"])
            
            # Add events to messages
            for event in result["events"]:
                st.session_state.messages.append({
                    'type': 'event',
                    'event_type': event['type'],
                    'content': event['data']['content'],
                    'timestamp': event['data']['timestamp'],
                    'metadata': event['data'].get('metadata', {})
                })
        
        # VÃ©rifier s'il y a une interruption
        if "__interrupt__" in result:
            st.session_state.workflow_state.update({
                'interrupted': True,
                'interrupt_data': result["__interrupt__"],
                'current_step': 'interrupted'
            })
            
            st.session_state.messages.append({
                'type': 'system',
                'content': 'Contenu gÃ©nÃ©rÃ© - En attente de rÃ©vision',
                'timestamp': time.time()
            })
        else:
            # Workflow terminÃ© sans interruption (ne devrait pas arriver dans ce cas)
            complete_workflow(result)
    
    except Exception as e:
        st.error(f"Erreur lors du traitement: {str(e)}")
        st.session_state.workflow_state['current_step'] = 'idle'
    
    st.rerun()

def resume_workflow(edited_content: str, human_feedback: str = ""):
    """Reprend le workflow avec le contenu Ã©ditÃ©"""
    
    config = {"configurable": {"thread_id": st.session_state.workflow_state['current_thread_id']}}
    
    try:
        with st.spinner("ğŸ”„ Finalisation en cours..."):
            # Reprendre avec Command(resume=...)
            resume_data = {
                "edited_content": edited_content,
                "human_feedback": human_feedback
            }
            
            final_result = st.session_state.graph.invoke(
                Command(resume=resume_data),
                config=config
            )
        
        # Process events from resumed workflow
        if "events" in final_result:
            # Update workflow state events
            update_workflow_events(final_result["events"])
            
            # Add events to messages
            for event in final_result["events"]:
                st.session_state.messages.append({
                    'type': 'event',
                    'event_type': event['type'],
                    'content': event['data']['content'],
                    'timestamp': event['data']['timestamp'],
                    'metadata': event['data'].get('metadata', {})
                })
        
        complete_workflow(final_result, human_feedback)
    
    except Exception as e:
        st.error(f"Erreur lors de la reprise: {str(e)}")

def reject_workflow(feedback: str = ""):
    """Rejette le workflow avec feedback"""
    
    st.session_state.messages.append({
        'type': 'system',
        'content': f'Workflow rejetÃ©. {feedback}',
        'timestamp': time.time()
    })
    
    reset_workflow()

def complete_workflow(result: Dict[str, Any], feedback: str = ""):
    """Termine le workflow avec succÃ¨s"""
    
    final_content = result.get("final_result", "Contenu non disponible")
    
    # Process any remaining events from the final result
    if "events" in result:
        # Update workflow state events
        update_workflow_events(result["events"])
        
        for event in result["events"]:
            # Only add events that haven't been processed yet
            event_id = f"{event['type']}_{event['data']['timestamp']}"
            existing_events = [msg for msg in st.session_state.messages if msg.get('type') == 'event']
            if not any(f"{msg['event_type']}_{msg['timestamp']}" == event_id for msg in existing_events):
                st.session_state.messages.append({
                    'type': 'event',
                    'event_type': event['type'],
                    'content': event['data']['content'],
                    'timestamp': event['data']['timestamp'],
                    'metadata': event['data'].get('metadata', {})
                })
    
    # Ajouter le rÃ©sultat final
    st.session_state.messages.append({
        'type': 'assistant',
        'content': final_content,
        'timestamp': time.time()
    })
    
    if feedback:
        st.session_state.messages.append({
            'type': 'system',
            'content': f'âœ… Workflow terminÃ© avec feedback: {feedback}',
            'timestamp': time.time()
        })
    else:
        st.session_state.messages.append({
            'type': 'system',
            'content': 'âœ… Workflow terminÃ© avec succÃ¨s',
            'timestamp': time.time()
        })
    
    # Sauvegarder dans l'historique
    execution_record = {
        'user_request': result.get('user_request', ''),
        'final_result': final_content,
        'timestamp': time.time(),
        'feedback': feedback
    }
    
    if 'execution_history' not in st.session_state.workflow_state:
        st.session_state.workflow_state['execution_history'] = []
    
    st.session_state.workflow_state['execution_history'].append(execution_record)
    
    # RÃ©initialiser l'Ã©tat
    st.session_state.workflow_state.update({
        'interrupted': False,
        'interrupt_data': None,
        'workflow_completed': True,
        'current_step': 'completed'
    })
    
    st.rerun()

def reset_workflow():
    """RÃ©initialise complÃ¨tement le workflow"""
    st.session_state.workflow_state = {
        'current_thread_id': None,
        'interrupted': False,
        'interrupt_data': None,
        'workflow_completed': False,
        'execution_history': st.session_state.workflow_state.get('execution_history', []),
        'current_step': 'idle',
        'events': []
    }
    st.session_state.messages = []
    st.rerun()

# Point d'entrÃ©e principal
if __name__ == "__main__":
    main()